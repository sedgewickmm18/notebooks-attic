{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: confluent_kafka is not installed. Publish to MessageHub not supported.\n"
     ]
    }
   ],
   "source": [
    "# Real life data\n",
    "\n",
    "import logging\n",
    "import threading\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.mplot3d import axes3d\n",
    "import seaborn as seabornInstance\n",
    "from sqlalchemy import Column, Integer, String, Float, DateTime, Boolean, func\n",
    "\n",
    "from iotfunctions import base\n",
    "from iotfunctions import bif\n",
    "from iotfunctions import entity\n",
    "from iotfunctions import metadata\n",
    "from iotfunctions.metadata import EntityType\n",
    "from iotfunctions.db import Database\n",
    "from iotfunctions.enginelog import EngineLogging\n",
    "from iotfunctions import estimator\n",
    "from iotfunctions.ui import (UISingle, UIMultiItem, UIFunctionOutSingle,\n",
    "                 UISingleItem, UIFunctionOutMulti, UIMulti, UIExpression,\n",
    "                 UIText, UIStatusFlag, UIParameters)\n",
    "from mmfunctions.anomaly import (SaliencybasedGeneralizedAnomalyScore, SpectralAnomalyScore,\n",
    "                 FFTbasedGeneralizedAnomalyScore, KMeansAnomalyScore)\n",
    "import datetime as dt\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, r2_score\n",
    "\n",
    "import scipy as sp\n",
    "import scipy.fftpack\n",
    "import skimage as ski\n",
    "\n",
    "from skimage import util as skiutil # for nifty windowing\n",
    "import pyod as pyod\n",
    "from pyod.utils.data import generate_data\n",
    "from pyod.utils.data import evaluate_print\n",
    "from pyod.utils.example import visualize\n",
    "from pyod.models.knn import KNN\n",
    "from pyod.models.iforest import IForest\n",
    "%matplotlib inline\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "EngineLogging.configure_console_logging(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train a 2-layered LSTM in Watson Machine Learning\n",
    "\n",
    " \n",
    "Telemanom ([Detecting Spacecraft Anomalies Using LSTMs and Nonparametric Dynamic Thresholding](https://arxiv.org/pdf/1802.04431.pdf) - 2018\n",
    "\n",
    "\n",
    "Let's find out first what ML libraries are supported by WML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/markus/src/mmfunctions', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/markus/.local/lib/python3.8/site-packages', '/usr/local/lib/python3.8/dist-packages', '/usr/lib/python3/dist-packages', '/usr/lib/python3/dist-packages/IPython/extensions', '/home/markus/.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print (sys.path)\n",
    " \n",
    "from ibm_watson_machine_learning import APIClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# make sure to downgrade to sklearn 0.22.2 (no >= 0.23)\n",
    "#from watson_machine_learning_client import WatsonMachineLearningAPIClient\n",
    "from ibm_watson_machine_learning import APIClient\n",
    "\n",
    "with open('credentials_wml.json', encoding='utf-8') as F:\n",
    "    wml_credentials = json.loads(F.read())\n",
    "    \n",
    "with open('credentials_cos.json', encoding='utf-8') as F:\n",
    "    cos_credentials = json.loads(F.read())\n",
    "\n",
    "#wml_url=wml_credentials['url']\n",
    "#wml_instance_id=wml_credentials['instance_id']\n",
    "#wml_apikey=wml_credentials['apikey']\n",
    "\n",
    "wml_data_source_type= 's3'\n",
    "\n",
    "\n",
    "# don't use this endpoint\n",
    "cos_endpoint = cos_credentials['endpoints']\n",
    "cos_endpoint = 'https://s3.eu.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "cos_apikey = cos_credentials['apikey']\n",
    "cos_access_key = cos_credentials['cos_hmac_keys']['access_key_id']\n",
    "cos_secret_key = cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "# 'https://s3.eu.cloud-object-storage.appdomain.cloud'\n",
    "\n",
    "cos_input_bucket = 'githubanalyzer-donotdelete-pr-b9xa3kxotzh5in'\n",
    "cos_output_bucket = 'githubanalyzer-donotdelete-pr-b9xa3kxotzh5in'\n",
    "\n",
    "client = APIClient(wml_credentials)\n",
    "#rep_list = client.runtimes.list(limit=4000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step \n",
    "\n",
    "Apparently Keras is missing out. However, Telemanom is built on Keras, so we have to port it to either Tensorflow, Pytorch, Mxnet, Caffe or Theano.\n",
    "\n",
    "I opted for Pytorch for skill building purposes and ported Telemanom to Pytorch.\n",
    "\n",
    "\n",
    "\n",
    "<small>\n",
    "    \n",
    "```\n",
    "    \n",
    "class LSTM_2L(nn.Module):\n",
    "    def __init__(self, n_features = 1, hidden_dims = [80,80], seq_length = 250,\n",
    "                 batch_size = 64, n_predictions = 10, dropout = 0.3):\n",
    "        super(LSTM_2L, self).__init__()\n",
    "        print ('LSTM_2L', n_features, hidden_dims, seq_length, batch_size, n_predictions, dropout)\n",
    "\n",
    "        self.n_features = n_features\n",
    "        self.hidden_dims = hidden_dims\n",
    "        self.seq_length = seq_length\n",
    "        self.num_layers = len(self.hidden_dims)\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.lstm1 = nn.LSTM(\n",
    "            input_size = self.n_features,\n",
    "            hidden_size = self.hidden_dims[0],\n",
    "            batch_first = True,\n",
    "            dropout = dropout,\n",
    "            num_layers = 2)\n",
    "\n",
    "        self.linear = nn.Linear(self.hidden_dims[1], n_predictions)\n",
    "        self.init_hidden_state()\n",
    "        \n",
    "    def init_hidden_state(self):\n",
    "\n",
    "        self.hidden = (\n",
    "            torch.randn(self.num_layers, self.batch_size, self.hidden_dims[0]), #.to(self.device),\n",
    "            torch.randn(self.num_layers, self.batch_size, self.hidden_dims[0]), #.to(self.device),\n",
    "            )\n",
    "\n",
    "    def forward(self, sequences):\n",
    "\n",
    "        batch_size, seq_len, n_features = sequences.size()  # batch first\n",
    "\n",
    "        lstm1_out , (h1_n, c1_n) = self.lstm1(sequences, (self.hidden[0], self.hidden[1]))\n",
    "\n",
    "        last_time_step = lstm1_out[:,-1,:]\n",
    "\n",
    "        y_pred = self.linear(last_time_step)\n",
    "\n",
    "        return y_pred\n",
    " ```\n",
    "</small>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part of mmfunctions\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "import telemanom\n",
    "from telemanom.helpers import Config\n",
    "from telemanom.errors import Errors\n",
    "import telemanom.helpers as helpers\n",
    "from telemanom.channel import Channel\n",
    "from telemanom.modeling import Model\n",
    "\n",
    "conf = Config(\"./telemanom/config.yaml\")\n",
    "\n",
    "conf.dictionary['l_s'] = 250\n",
    "conf.dictionary['epochs'] = 80\n",
    "conf.dictionary['dropout'] = 0.2\n",
    "conf.batch_size = 512\n",
    "conf.l_s = 250\n",
    "conf.epochs = 80    # max\n",
    "conf.dropout = 0.2\n",
    "conf.lstm_batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Channel:Channel\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Define structure for local data\n",
    "#              telemanom supports multiple channels to reflect spacecraft sensors, we only need a single one now\n",
    "#\n",
    "device=\"Armstarknew\"\n",
    "chan = Channel(conf, device)\n",
    "helpers.make_dirs(conf.use_id, conf, \"./telemanom\")\n",
    "print(chan)\n",
    "conf\n",
    "\n",
    "# load data\n",
    "\n",
    "chan.train = np.loadtxt('./telemanom/wml_train.csv')\n",
    "chan.test = np.loadtxt('./telemanom/wml_test.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The following steps replay the code in wml_telemanom.py\n",
    "\n",
    "We jump over the next few cells unless we want to initiate a local training run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-10-23T13:43:23.919 INFO telemanom.shape_data FFT channel: False\n",
      "(129300, 2)\n",
      "2020-10-23T13:43:24.330 INFO telemanom.shape_data FFT channel: False\n",
      "(129195, 2)\n"
     ]
    }
   ],
   "source": [
    "# producing overlapping windows of length 260 for lookback (250) and prediction (10)\n",
    "chan.shape_data(chan.train, train=True)\n",
    "chan.shape_data(chan.test, train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM_2L 2 [80, 80] 250 64 10 0.2\n",
      "Hidden dimensions are:  2 64 80\n",
      "input shape:  (None, 2)\n"
     ]
    }
   ],
   "source": [
    "# init the Python double stacked LSTM model\n",
    "model = Model(conf, conf.use_id, chan, \"./telemanom\", False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.model.hidden[0].clone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "trainPath = './mytrainedpytorchmodel'\n",
    "\n",
    "try:\n",
    "    model.model.load_state_dict(torch.load(trainPath))\n",
    "    model.model.eval()\n",
    "except Exception:\n",
    "    # drink a coffee - training takes roughly 30 minutes\n",
    "    print('have to train')\n",
    "    model.train_new(chan)\n",
    "    torch.save(model.model.state_dict(), trainPath)\n",
    "\n",
    "#model.train_new(chan)\n",
    "torch.save(model.model.state_dict(), \"./mytrainedpytorchmodel\")\n",
    "\n",
    "# no training run - we've already spent CPU cycles last week\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.2770,  0.3517,  0.3657,  ...,  0.9333,  0.8008,  0.0585],\n",
       "          [ 0.9082,  1.0697,  0.9857,  ...,  0.6168,  0.9432, -0.6597],\n",
       "          [-0.9625, -0.2237,  1.0262,  ..., -0.1932,  0.9379, -0.7841],\n",
       "          ...,\n",
       "          [ 0.0493,  0.9457,  0.1089,  ..., -0.1914,  0.5980, -1.1544],\n",
       "          [ 1.6777, -1.2699,  3.0124,  ...,  0.5711,  0.5023, -0.6240],\n",
       "          [ 1.2568, -1.0925, -0.7639,  ...,  0.4809,  0.2299, -0.8175]],\n",
       " \n",
       "         [[ 0.3506,  1.2182,  0.7459,  ..., -0.0674, -0.0940, -0.7716],\n",
       "          [ 0.3497, -0.2151,  1.3165,  ...,  0.0836, -1.5290, -1.0644],\n",
       "          [-0.5695,  0.0111,  0.6651,  ...,  0.2094, -0.6777, -1.1934],\n",
       "          ...,\n",
       "          [ 0.1078, -0.9688, -0.8398,  ...,  0.5635, -0.0361, -0.3012],\n",
       "          [-0.9514,  0.0604,  1.7998,  ...,  2.3432,  0.9794, -0.4232],\n",
       "          [-1.5975, -0.2508,  0.8103,  ..., -1.0329,  2.1255, -1.2002]]]),\n",
       " tensor([[[ 0.2770,  0.3517,  0.3657,  ...,  0.9333,  0.8008,  0.0585],\n",
       "          [ 0.9082,  1.0697,  0.9857,  ...,  0.6168,  0.9432, -0.6597],\n",
       "          [-0.9625, -0.2237,  1.0262,  ..., -0.1932,  0.9379, -0.7841],\n",
       "          ...,\n",
       "          [ 0.0493,  0.9457,  0.1089,  ..., -0.1914,  0.5980, -1.1544],\n",
       "          [ 1.6777, -1.2699,  3.0124,  ...,  0.5711,  0.5023, -0.6240],\n",
       "          [ 1.2568, -1.0925, -0.7639,  ...,  0.4809,  0.2299, -0.8175]],\n",
       " \n",
       "         [[ 0.3506,  1.2182,  0.7459,  ..., -0.0674, -0.0940, -0.7716],\n",
       "          [ 0.3497, -0.2151,  1.3165,  ...,  0.0836, -1.5290, -1.0644],\n",
       "          [-0.5695,  0.0111,  0.6651,  ...,  0.2094, -0.6777, -1.1934],\n",
       "          ...,\n",
       "          [ 0.1078, -0.9688, -0.8398,  ...,  0.5635, -0.0361, -0.3012],\n",
       "          [-0.9514,  0.0604,  1.7998,  ...,  2.3432,  0.9794, -0.4232],\n",
       "          [-1.5975, -0.2508,  0.8103,  ..., -1.0329,  2.1255, -1.2002]]]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x, model.model.hidden[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.state_dict of LSTM_2L(\n",
       "  (lstm1): LSTM(2, 80, num_layers=2, batch_first=True, dropout=0.2)\n",
       "  (linear): Linear(in_features=80, out_features=10, bias=True)\n",
       ")>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.model.state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "forward| Batch size:  64  Sequence length:  80 Output length: 2\n",
      "Shapes  torch.Size([64, 80, 80]) torch.Size([64, 80]) torch.Size([64, 80])\n",
      "forward| Batch size:  tensor(64)  Sequence length:  tensor(80) Output length: tensor(2)\n",
      "Shapes  torch.Size([64, 80, 80]) torch.Size([64, 80]) torch.Size([64, 80])\n",
      "name: \"input.1\"\n",
      "type {\n",
      "  tensor_type {\n",
      "    elem_type: 1\n",
      "    shape {\n",
      "      dim {\n",
      "        dim_value: 64\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 80\n",
      "      }\n",
      "      dim {\n",
      "        dim_value: 2\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# attempt to export it as ONNX model\n",
    "\n",
    "# switch off training mode\n",
    "model.model.eval()\n",
    "\n",
    "torch_in = None\n",
    "torch_out = None\n",
    "\n",
    "# switch off autograd, automatic differentiation\n",
    "with torch.no_grad():\n",
    "    \n",
    "    # input tensor\n",
    "    torch_in = torch.randn(64, 80, 2, requires_grad=True)\n",
    "    \n",
    "    # test dimensions\n",
    "    torch_out,_ = model.model(torch_in)\n",
    "\n",
    "    # default export\n",
    "    torch.onnx.export(model.model, torch_in, 'lstm.onnx')\n",
    "    \n",
    "    # test model load\n",
    "    import onnx\n",
    "    onnx_model = onnx.load('lstm.onnx')\n",
    "    # input shape [5, 3, 10]\n",
    "    print(onnx_model.graph.input[0])\n",
    "\n",
    "    onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running onnx models\n",
    "\n",
    "Following the descriptions found here:\n",
    "- https://pytorch.org/tutorials/advanced/super_resolution_with_onnxruntime.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes  (64, 10) (64, 10)\n",
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession('lstm.onnx')\n",
    "\n",
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()\n",
    "\n",
    "# compute ONNX Runtime output prediction\n",
    "#   reuse torch_in and torch_out from previous model exporting step\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(torch_in)}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "\n",
    "print ('Shapes ', ort_outs[0].shape, to_numpy(torch_out).shape)\n",
    "\n",
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(torch_out), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<strong>Make sure you have uploaded the code in mmfunctions/telemanom as zip file to COS bucket</strong><br/>githubanalyzer-donotdelete-pr-b9xa3kxotzh5in"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "Markdown('<strong>{}</strong><br/>{}'.format('Make sure you have uploaded the code in mmfunctions/telemanom as zip file to COS bucket', cos_input_bucket))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<strong>./telemanom/wml_model.zip\n",
       "found - good</strong><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Zip the code in the ./telemanom subdirectory first\n",
    "\n",
    "import subprocess\n",
    "output = None\n",
    "try:\n",
    "    output = subprocess.check_output(\"ls ./telemanom/wml_model.zip\", shell=True).decode('ascii')  + 'found - good'\n",
    "except Exception:\n",
    "    output = 'Not found - do it now and run \\\"zip -x \\'.git*\\' -9ry wml_model.zip  .\\\" in the telemanom directory'\n",
    "\n",
    "Markdown('<strong>{}</strong><br/>'.format(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/_wml_checkpoints/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/aa89ed23-1022-4496-a0c7-af0f8c24e3fb/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/f26b7329-c348-4346-922b-a23cc37f2a10/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/notebook/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-JzhNf7pMR/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-gLNZB7tGg/\r\n",
      "                          DIR  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-p8oQfTDMR/\r\n",
      "2020-08-05 13:12      3563355  s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/wml_model.zip\r\n"
     ]
    }
   ],
   "source": [
    "# check whether we have uploaded the code\n",
    "!/home/markus/.local/bin/s3cmd --access_key {cos_access_key} --secret_key {cos_secret_key} \\\n",
    "--access_token {cos_apikey} --host s3.eu.cloud-object-storage.appdomain.cloud --host-bucket=s3.eu.cloud-object-storage.appdomain.cloud \\\n",
    "ls s3://githubanalyzer-donotdelete-pr-b9xa3kxotzh5in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now starting to work with WML\n",
    "#\n",
    "#   make sure we go with Open Neural Network Exchange (ONNX) to allow for pytorch model exporting\n",
    "# \n",
    "\n",
    "wml_train_code='./telemanom/wml_model.zip' # where this notebook finds the code\n",
    "\n",
    "wml_execution_command='python3 wml_telemanom.py' # command to start training\n",
    "\n",
    "wml_framework_name='pytorch-onnx'\n",
    "\n",
    "# we have to run on pytorch-onnx 1.2 (Open Neural Network Exchange) but it's not yet available\n",
    "wml_framework_version='1.3'   # go with 1.1 until GA of CloudPak for Data 3.5 \n",
    "wml_runtime = 'python'\n",
    "wml_runtime_version='3.6' # and python 3.6\n",
    "\n",
    "# pytorch-onnx_1.2\n",
    "\n",
    "wml_run_definition = 'wml-pytorch-definition' # dummy name\n",
    "wml_run_name = 'wml-pytorch-run' # more dummy\n",
    "wml_model_name='wml-tensorflow-miregal' # even more dummy\n",
    "\n",
    "wml_compute_name='k80'  # free tier machine type\n",
    "wml_compute_nodes='1'   # free tier\n",
    "\n",
    "wml_runtime_version_v4 = wml_framework_version + '-py' + wml_runtime_version   # sdk level\n",
    "wml_compute_nodes_v4 = int(wml_compute_nodes)\n",
    "\n",
    "model_code = wml_train_code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./telemanom/wml_model.zip'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wml_train_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  -------------  ------------------------\n",
      "ID                                    NAME           CREATED\n",
      "86ad7b6f-3230-4966-be4d-5c7e80519e83  WML Armstrong  2020-09-04T09:54:29.345Z\n",
      "------------------------------------  -------------  ------------------------\n"
     ]
    }
   ],
   "source": [
    "space_id = '86ad7b6f-3230-4966-be4d-5c7e80519e83'\n",
    "client.set.default_space(space_id)\n",
    "client.spaces.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_definition_metadata = {\n",
    "    client.model_definitions.ConfigurationMetaNames.NAME: \"pytorch-telemanom\",\n",
    "    client.model_definitions.ConfigurationMetaNames.DESCRIPTION: \"pytorch-telemanom\",\n",
    "    client.model_definitions.ConfigurationMetaNames.COMMAND:  wml_execution_command,\n",
    "    client.model_definitions.ConfigurationMetaNames.PLATFORM: {\"name\": \"python\", \"versions\": [\"3.6\"]},\n",
    "    client.model_definitions.ConfigurationMetaNames.VERSION: \"2.0\",\n",
    "    client.model_definitions.ConfigurationMetaNames.SPACE_UID: space_id\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1c30f95-ac3c-46de-9d90-731aec7abf93\n"
     ]
    }
   ],
   "source": [
    "definition_details = client.model_definitions.store(wml_train_code, model_definition_metadata)\n",
    "model_definition_id = client.model_definitions.get_id(definition_details)\n",
    "print(model_definition_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------  --------------------  ------------------------------------\n",
      "NAME               ASSET_TYPE            GUID\n",
      "pytorch-telemanom  wml_model_definition  84cc3aaa-f935-4cf5-9089-439048e58335\n",
      "pytorch-telemanom  wml_model_definition  a1c30f95-ac3c-46de-9d90-731aec7abf93\n",
      "pytorch-telemanom  wml_model_definition  a66a715b-841e-4249-9d3a-b1de90a02859\n",
      "pytorch-telemanom  wml_model_definition  0b974b2f-10f7-4ed4-a2c9-317c4da2e0aa\n",
      "-----------------  --------------------  ------------------------------------\n"
     ]
    }
   ],
   "source": [
    "client.model_definitions.list(limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client.model_definitions.delete('84cc3aaa-f935-4cf5-9089-439048e58335')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_metadata = training_metadata = {\n",
    "   client.training.ConfigurationMetaNames.NAME: \"pytorch-telemanom\",\n",
    "    client.training.ConfigurationMetaNames.SPACE_UID: space_id,\n",
    "    client.training.ConfigurationMetaNames.DESCRIPTION: \"pytorch-telemanom\",\n",
    "    client.training.ConfigurationMetaNames.TAGS :[{\n",
    "      \"value\": \"wml_execution_command\",\n",
    "      \"description\": \"PyTorch Telemanom anomaly detection\"\n",
    "    }],\n",
    "    client.training.ConfigurationMetaNames.TRAINING_RESULTS_REFERENCE:  {\n",
    "    \"name\": \"pytorch-telemanom\",\n",
    "    \"connection\": {\n",
    "            \"endpoint_url\": cos_endpoint,\n",
    "            \"access_key_id\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "            \"secret_access_key\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "      },\n",
    "      \"location\": {\n",
    "        \"bucket\": cos_output_bucket\n",
    "      },\n",
    "    \"type\": \"s3\"\n",
    "  },\n",
    "  client.training.ConfigurationMetaNames.MODEL_DEFINITION:{\n",
    "        \"id\": model_definition_id,\n",
    "        \"command\":  wml_execution_command,\n",
    "        \"hardware_spec\": {\n",
    "          \"name\": \"K80\",\n",
    "          \"nodes\": 1\n",
    "        },\n",
    "        \"software_spec\": {\n",
    "          \"name\": \"pytorch-onnx_1.3-py3.6\"  # 1.3 has no pandas installed\n",
    "        },\n",
    "        \"parameters\": {\n",
    "          \"name\": \"wml_execution_command\",\n",
    "          \"description\": \"PyTorch Telemanom anomaly detection\"\n",
    "        }\n",
    "  },\n",
    "  client.training.ConfigurationMetaNames.TRAINING_DATA_REFERENCES: [\n",
    "       {\n",
    "      \"name\": \"training_input_data\",\n",
    "      \"type\": \"s3\",\n",
    "      \"connection\": {\n",
    "        \"endpoint_url\": cos_endpoint,\n",
    "        \"access_key_id\": cos_credentials['cos_hmac_keys']['access_key_id'],\n",
    "        \"secret_access_key\": cos_credentials['cos_hmac_keys']['secret_access_key']\n",
    "      },\n",
    "      \"location\": {\n",
    "        \"bucket\": cos_input_bucket\n",
    "      },\n",
    "      \"schema\": {\n",
    "        \"id\":\"idmlp_schema\",\n",
    "        \"fields\": [\n",
    "          {\n",
    "            \"name\": \"text\",\n",
    "            \"type\": \"string\"\n",
    "          }\n",
    "        ]\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc7c3542-5665-4a72-a85b-0a7680ec90f4\n"
     ]
    }
   ],
   "source": [
    "training = client.training.run(training_metadata)\n",
    "training_id = client.training.get_uid(training)\n",
    "print(training_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'state': 'pending'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training_id = '15a936b6-011d-47b9-bb27-a4b656d23ed3'\n",
    "client.training.get_status(training_id) #['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------  ---------  ------------------------\n",
      "GUID (training)                       STATE      CREATED\n",
      "fc7c3542-5665-4a72-a85b-0a7680ec90f4  completed  2020-10-23T11:45:08.301Z\n",
      "------------------------------------  ---------  ------------------------\n"
     ]
    }
   ],
   "source": [
    "client.training.list(limit=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in case something went wrong, cancel and delete\n",
    "#client.training.cancel('5a51f09e-c8cb-4685-9bf2-779d199fa879', hard_delete=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692a6a4d-2c4d-45ff-a1ed-b167ee55469a\n"
     ]
    }
   ],
   "source": [
    "#software_spec_uid = client.software_specifications.get_id_by_name(\"pytorch-onnx_1.2-py3.6\")\n",
    "#print (software_spec_uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'custom_library_uid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-dfbeba479245>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m                 \u001b[0;34m\"description\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwml_run_definition\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;34m\"command\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwml_execution_command\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m                 \u001b[0;34m\"training_lib_href\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"/v4/libraries/\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mcustom_library_uid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \"compute\": {\n\u001b[1;32m     27\u001b[0m                     \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwml_compute_name\u001b[0m\u001b[0;34m,\u001b[0m            \u001b[0;31m# specify where to run it (not that I have a choice)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'custom_library_uid' is not defined"
     ]
    }
   ],
   "source": [
    "#\n",
    "#  Pipelines define a sequence of operations\n",
    "#\n",
    "# define a pipeline with a single entry (node) for the training run\n",
    "#  we could add more node for scaling/normalizing, imputation, feature extraction, \"you name it\"\n",
    "#\n",
    "doc = {\n",
    "    \"doc_type\": \"pipeline\",\n",
    "    \"version\": \"2.0\",\n",
    "    \"primary_pipeline\": wml_framework_name,\n",
    "    \"pipelines\": [{\n",
    "        \"id\": wml_framework_name,\n",
    "        \"runtime_ref\": \"hybrid\",\n",
    "        \"nodes\": [{\n",
    "            \"id\": \"training\",\n",
    "            \"type\": \"model_node\",\n",
    "            \"op\": \"dl_train\",\n",
    "            \"runtime_ref\": wml_run_name,\n",
    "            \"inputs\": [],\n",
    "            \"outputs\": [],\n",
    "            \"parameters\": {\n",
    "                \"name\": \"pytorch-telemanom\",\n",
    "                \"description\": wml_run_definition,\n",
    "                \"command\": wml_execution_command,\n",
    "                \"training_lib_href\": \"/v4/libraries/\"+custom_library_uid,\n",
    "                \"compute\": {\n",
    "                    \"name\": wml_compute_name,            # specify where to run it (not that I have a choice)\n",
    "                    \"nodes\": wml_compute_nodes_v4\n",
    "                }\n",
    "            }\n",
    "        }]\n",
    "    }],\n",
    "    \"runtimes\": [{\n",
    "        \"id\": wml_run_name,\n",
    "        \"name\": wml_framework_name,         # run it on a pytorch image\n",
    "        \"version\": wml_runtime_version_v4\n",
    "    }]\n",
    "}\n",
    "\n",
    "# put it in metadata object\n",
    "metadata = {\n",
    "    client.repository.PipelineMetaNames.NAME: wml_run_name,\n",
    "    client.repository.PipelineMetaNames.DOCUMENT: doc\n",
    "}\n",
    "\n",
    "# and create the pipeline\n",
    "pipeline_id = client.pipelines.get_uid(client.repository.store_pipeline(meta_props=metadata))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'name': 'wml-pytorch-run',\n",
       "  'guid': 'fb11e3a0-b123-4551-9225-28ff94146536',\n",
       "  'rev': '503e3bb5-8d87-43e4-9b13-8265b09fa190',\n",
       "  'id': 'fb11e3a0-b123-4551-9225-28ff94146536',\n",
       "  'modified_at': '2020-08-05T17:37:16.224Z',\n",
       "  'created_at': '2020-08-05T17:37:16.159Z',\n",
       "  'href': '/v4/pipelines/fb11e3a0-b123-4551-9225-28ff94146536?rev=503e3bb5-8d87-43e4-9b13-8265b09fa190'},\n",
       " 'entity': {'space': {'id': '88740b60-6b2f-4f74-b6d8-20528d14db8b',\n",
       "   'href': '/v4/spaces/88740b60-6b2f-4f74-b6d8-20528d14db8b'},\n",
       "  'name': 'wml-pytorch-run',\n",
       "  'document': {'doc_type': 'pipeline',\n",
       "   'version': '2.0',\n",
       "   'pipelines': [{'id': 'pytorch-onnx',\n",
       "     'runtime_ref': 'hybrid',\n",
       "     'nodes': [{'outputs': [],\n",
       "       'id': 'training',\n",
       "       'inputs': [],\n",
       "       'type': 'model_node',\n",
       "       'parameters': {'name': 'pytorch-telemanom',\n",
       "        'description': 'wml-pytorch-definition',\n",
       "        'compute': {'name': 'k80', 'nodes': 1},\n",
       "        'command': 'python3 wml_telemanom.py',\n",
       "        'training_lib_href': '/v4/libraries/017d6899-e8eb-4b89-a409-b843f741afe0'},\n",
       "       'runtime_ref': 'wml-pytorch-run',\n",
       "       'op': 'dl_train'}]}],\n",
       "   'runtimes': [{'id': 'wml-pytorch-run',\n",
       "     'name': 'pytorch-onnx',\n",
       "     'version': '1.2-py3.6'}],\n",
       "   'primary_pipeline': 'pytorch-onnx'}}}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is my pipeline now\n",
    "client.pipelines.get_details(pipeline_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-05T19:37:18.138 WARNING watson_machine_learning_client.wml_client_error.__init__ Failure during training. (POST https://eu-de.ml.cloud.ibm.com/v4/trainings)\n",
      "Status code: 400, body: {\n",
      "  \"trace\": \"774c7e4e470ee9465a943e8c92d97d47\",\n",
      "  \"errors\": [{\n",
      "    \"code\": \"bad_request\",\n",
      "    \"message\": \"Unsupported training runtime pytorch-onnx_1.2-py3.6\"\n",
      "  }]\n",
      "}\n"
     ]
    },
    {
     "ename": "ApiRequestFailure",
     "evalue": "Failure during training. (POST https://eu-de.ml.cloud.ibm.com/v4/trainings)\nStatus code: 400, body: {\n  \"trace\": \"774c7e4e470ee9465a943e8c92d97d47\",\n  \"errors\": [{\n    \"code\": \"bad_request\",\n    \"message\": \"Unsupported training runtime pytorch-onnx_1.2-py3.6\"\n  }]\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mApiRequestFailure\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-3d51210104ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m }\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtraining_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta_props\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get status\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/training.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, meta_props, asynchronous)\u001b[0m\n\u001b[1;32m    395\u001b[0m                                                     headers=self._client._get_headers(), verify=False)\n\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m         \u001b[0mrun_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'training'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse_train_post\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0mtrained_model_guid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_details\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/wml_resource.py\u001b[0m in \u001b[0;36m_handle_response\u001b[0;34m(self, expected_status_code, operationName, response, json_response)\u001b[0m\n\u001b[1;32m     59\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mApiRequestFailure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'Failure during {}.'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moperationName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mApiRequestFailure\u001b[0m: Failure during training. (POST https://eu-de.ml.cloud.ibm.com/v4/trainings)\nStatus code: 400, body: {\n  \"trace\": \"774c7e4e470ee9465a943e8c92d97d47\",\n  \"errors\": [{\n    \"code\": \"bad_request\",\n    \"message\": \"Unsupported training runtime pytorch-onnx_1.2-py3.6\"\n  }]\n}"
     ]
    }
   ],
   "source": [
    "# \n",
    "# finally start the training run for v4\n",
    "#   tell it where to load data and model code from and dump results to\n",
    "#\n",
    "metadata = {\n",
    "    client.training.ConfigurationMetaNames.TRAINING_RESULTS_REFERENCE: {\n",
    "        \"name\": \"training-results-reference_name\",\n",
    "        \"connection\": {\n",
    "            \"endpoint_url\": cos_endpoint,\n",
    "            \"access_key_id\": cos_access_key,\n",
    "            \"secret_access_key\": cos_secret_key\n",
    "        },\n",
    "        \"location\": {\n",
    "            \"bucket\": cos_output_bucket\n",
    "        },\n",
    "        \"type\": wml_data_source_type\n",
    "    },\n",
    "    client.training.ConfigurationMetaNames.TRAINING_DATA_REFERENCES:[{\n",
    "        \"name\": \"training_input_data\",\n",
    "        \"type\": wml_data_source_type,\n",
    "        \"connection\": {\n",
    "            \"endpoint_url\": cos_endpoint,\n",
    "            \"access_key_id\": cos_access_key,\n",
    "            \"secret_access_key\": cos_secret_key\n",
    "        },\n",
    "        \"location\": {\n",
    "            \"bucket\": cos_input_bucket\n",
    "        }\n",
    "    }],\n",
    "    client.training.ConfigurationMetaNames.PIPELINE_UID: pipeline_id\n",
    "}\n",
    "\n",
    "training_id = client.training.get_uid(client.training.run(meta_props=metadata))\n",
    "print(\"training_id\", client.training.get_details(training_id))\n",
    "print(\"get status\", client.training.get_status(training_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "run_details = client.training.get_details(training_id)\n",
    "run_uid = training_id\n",
    "\n",
    "# print logs\n",
    "\n",
    "client.training.monitor_logs(run_uid)\n",
    "client.training.monitor_metrics(run_uid)\n",
    "\n",
    "# should not have run after restarting the notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'message': {'text': 'Node training: Shapes  torch.Size([64, 250, 80]) torch.Size([64, 80]) torch.Size([64, 80])\\n',\n",
       "  'level': 'info'},\n",
       " 'running_at': '2020-08-05T13:14:37.894Z',\n",
       " 'state': 'running'}"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#run_uid='2c002ed8-e508-4f20-bb15-b789f39a6974'\n",
    "status = client.training.get_status(run_uid)\n",
    "status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SUCCESS'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#client.training.cancel(run_uid)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### if training seems to have failed, just look at the logs in our COS output bucket\n",
    "\n",
    "Dumb me, in the previous run I forgot to import sys.\n",
    "\n",
    "Fortunately model training has succeeded and the model has been stored in COS. Phew.\n",
    "\n",
    "<small>\n",
    "\n",
    "```\n",
    "...\n",
    "Batch  1611\n",
    "Batch  1612\n",
    "After batch  1612 0.002384878075476655\n",
    "[1] Training loss: 0.002384878075476655 \t Validation loss: 0.0014487287297119242 \n",
    "Training complete...\n",
    "Model saved in file: /mnt/results/githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-h9VOfZVMR/model\n",
    "['_submitted_code', 'learner-1', 'model', 'training-log.txt']\n",
    "/mnt/results/githubanalyzer-donotdelete-pr-b9xa3kxotzh5in/training-h9VOfZVMR\n",
    "Traceback (most recent call last):\n",
    "  File \"wml_telemanom.py\", line 61, in <module>\n",
    "    sys.stdout.flush()\n",
    "NameError: name 'sys' is not defined\n",
    "```\n",
    "    \n",
    "</small>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.1-py3.6'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wml_runtime_version_v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's store the model\n",
    "\n",
    "meta_props_pyt = {\n",
    "    client.repository.ModelMetaNames.NAME: wml_model_name,\n",
    "    client.repository.ModelMetaNames.RUNTIME_UID: wml_framework_name + '_' + wml_runtime_version_v4,\n",
    "    client.repository.ModelMetaNames.TYPE: wml_framework_name + '_' + wml_framework_version\n",
    "}\n",
    "\n",
    "model_details = client.repository.store_model(run_uid, meta_props=meta_props_pyt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'metadata': {'name': 'wml-tensorflow-miregal',\n",
       "  'guid': 'eeac7d0a-69e7-4f81-ac5b-35eff542a841',\n",
       "  'rev': 'cea0af8b-0ebf-4e0e-88d9-69b98c78eefe',\n",
       "  'id': 'eeac7d0a-69e7-4f81-ac5b-35eff542a841',\n",
       "  'modified_at': '2020-07-27T14:55:59.286Z',\n",
       "  'created_at': '2020-07-27T14:55:59.219Z',\n",
       "  'href': '/v4/models/eeac7d0a-69e7-4f81-ac5b-35eff542a841?rev=cea0af8b-0ebf-4e0e-88d9-69b98c78eefe'},\n",
       " 'entity': {'name': 'wml-tensorflow-miregal',\n",
       "  'content_status': {'state': 'persisting'},\n",
       "  'import': {'location': {'training': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b',\n",
       "    'pipeline_model': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/pipeline-model.json',\n",
       "    'training_status': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/training-status.json',\n",
       "    'pipeline': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/pipeline.json',\n",
       "    'bucket': 'githubanalyzer-donotdelete-pr-b9xa3kxotzh5in',\n",
       "    'assets_path': '3dd32ad4-d6bf-45be-b09f-cf2b79e75e7b/assets'},\n",
       "   'type': 's3',\n",
       "   'connection': {'access_key_id': 'cc04444c99374c9e9589b8f85e931323',\n",
       "    'secret_access_key': '1a5062d937b09507a05b521a41b8baf6848c0cd6936e2864',\n",
       "    'endpoint_url': 'https://control.cloud-object-storage.cloud.ibm.com/v2/endpoints'}},\n",
       "  'space': {'id': '88740b60-6b2f-4f74-b6d8-20528d14db8b',\n",
       "   'href': '/v4/spaces/88740b60-6b2f-4f74-b6d8-20528d14db8b'},\n",
       "  'type': 'pytorch_1.1',\n",
       "  'runtime': {'id': 'pytorch_1.1-py3.6',\n",
       "   'href': '/v4/runtimes/pytorch_1.1-py3.6'}}}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}\n",
      "\n",
      "\n",
      "--------------------------\n",
      "Deployment creation failed\n",
      "--------------------------\n",
      "\n",
      "\n",
      "2020-07-27T17:00:12.499 WARNING watson_machine_learning_client.wml_client_error.__init__ Deployment creation failed. Error: 400. {\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}\n"
     ]
    },
    {
     "ename": "WMLClientError",
     "evalue": "Deployment creation failed. Error: 400. {\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWMLClientError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-3e5ef74ce1e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConfigurationMetaNames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONLINE\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     }\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdeployment_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_details\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'metadata'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta_props\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdeployment_details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/deployments.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, artifact_uid, meta_props, rev_id, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                 \u001b[0mprint_text_header_h2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mWMLClientError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msg\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. Error: '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'. '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;31m#return self._handle_response(202, u'created deployment', response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mWMLClientError\u001b[0m: Deployment creation failed. Error: 400. {\"trace\":\"-sulpksdfbwj8\",\"errors\":[{\"code\":\"unsupported_framework_details\",\"message\":\"Models of framework pytorch are not supported.\"}]}"
     ]
    }
   ],
   "source": [
    "#\n",
    "# finally let's deploy it\n",
    "#   use model name as deployment name\n",
    "#\n",
    "meta_props = {\n",
    "        client.deployments.ConfigurationMetaNames.NAME: wml_model_name,\n",
    "        client.deployments.ConfigurationMetaNames.ONLINE: {}\n",
    "    }\n",
    "deployment_details = client.deployments.create(model_details['metadata']['id'], meta_props)\n",
    "deployment_details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-07-27T16:57:28.619 WARNING watson_machine_learning_client.wml_client_error.__init__ Unexpected type of 'model_uid', expected: '<class 'str'>', actual: '<class 'dict'>'.\n"
     ]
    },
    {
     "ename": "UnexpectedType",
     "evalue": "Unexpected type of 'model_uid', expected: '<class 'str'>', actual: '<class 'dict'>'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedType\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-3a037dc416c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel_details\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepository\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_model_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/repository.py\u001b[0m in \u001b[0;36mget_model_details\u001b[0;34m(self, model_uid, limit)\u001b[0m\n\u001b[1;32m   1040\u001b[0m         \"\"\"\n\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1042\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_details\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mdocstring_parameter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'str_type'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSTR_TYPE_NAME\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/models.py\u001b[0m in \u001b[0;36mget_details\u001b[0;34m(self, model_uid, limit)\u001b[0m\n\u001b[1;32m   1462\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_if_either_is_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m         \u001b[0mmodel_uid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr_type_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m         \u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_uid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'model_uid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSTR_TYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1465\u001b[0m         \u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mu'limit'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/watson_machine_learning_client/wml_resource.py\u001b[0m in \u001b[0;36m_validate_type\u001b[0;34m(el, el_name, expected_type, mandatory)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mUnexpectedType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedType\u001b[0m: Unexpected type of 'model_uid', expected: '<class 'str'>', actual: '<class 'dict'>'."
     ]
    }
   ],
   "source": [
    "model_uid = model_details\n",
    "model_details = client.repository.get_model_details(model_uid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WTF ?\n",
    "```\n",
    "Training a PyTorch model using the Watson Machine Learning training service is supported, but deploying a trained PyTorch model in your Watson Machine Learning service is not supported.\n",
    "```\n",
    "https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/pm_service_supported_frameworks.html\n",
    "\n",
    "it took me by surprise: \n",
    "\n",
    "* WML doesn't support training Keras models in the cloud, but you can upload the h5 model and treat it as a tensorflow model\n",
    "\n",
    "Fortunately there is the wml_dev slack channel as last resort ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training parameters\n",
    "\n",
    "```\n",
    "loss_metric: 'mse'    # minimize mean square error\n",
    "optimizer: 'adam'     # sort of adaptive stochastic gradient descent\n",
    "validation_split: 0.2 # 20% of the data is used for validating (val_loss)\n",
    "dropout: 0.3          # ditch 30% of the LSTMs results when minimizing the loss function to avoid overfitting\n",
    "lstm_batch_size: 64   # number of training data batches to evaluate per optimizer run to update the model’s parameters\n",
    "\n",
    "patience: 10          # try at least 10 times to decrease val_loss smaller by ...\n",
    "min_delta: 0.0003     # ... at least min_delta, else stop, so we get at least 'patience' epochs\n",
    "epochs: 35            # no more than 35 passes through the entier training dataset.\n",
    "\n",
    "l_s: 250              # lookback: num previous timesteps provided to model to predict future values\n",
    "n_predictions: 10     # number of steps ahead to predict\n",
    "```\n",
    "\n",
    "This is defined in `telemanom/config.yaml`\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
