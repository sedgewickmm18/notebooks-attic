{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sparkify - Churn Prediction with PySpark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Intro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import udf, col, concat, count, lit, avg, lag, first, last, when\n",
    "from pyspark.sql.functions import min as Fmin, max as Fmax, sum as Fsum, round as Fround\n",
    "\n",
    "from pyspark.sql.types import IntegerType, DateType, TimestampType\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import VectorAssembler, Normalizer, StandardScaler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.classification import LogisticRegression, RandomForestClassifier, GBTClassifier\n",
    "from pyspark.ml.clustering import KMeans\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Java gateway process exited before sending its port number",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-369c2d24f6c6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Create a Spark Session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mspark\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkSession\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbuilder\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmaster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spark://10.152.183.12:7077\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/sql/session.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m                             \u001b[0msparkConf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                         \u001b[0;31m# This SparkContext may be an existing one.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m                         \u001b[0msc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetOrCreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparkConf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m                     \u001b[0;31m# Do not update `SparkConf` for existing `SparkContext`, as it's shared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m                     \u001b[0;31m# by all sessions.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36mgetOrCreate\u001b[0;34m(cls, conf)\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 384\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mSparkConf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    385\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_active_spark_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, master, appName, sparkHome, pyFiles, environment, batchSize, serializer, conf, gateway, jsc, profiler_cls)\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \" is not allowed as it is a security risk.\")\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgateway\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgateway\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m             self._do_init(master, appName, sparkHome, pyFiles, environment, batchSize, serializer,\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/context.py\u001b[0m in \u001b[0;36m_ensure_initialized\u001b[0;34m(cls, instance, gateway, conf)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgateway\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlaunch_gateway\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m                 \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jvm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSparkContext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gateway\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjvm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.9/site-packages/pyspark/java_gateway.py\u001b[0m in \u001b[0;36mlaunch_gateway\u001b[0;34m(conf, popen_kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Java gateway process exited before sending its port number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn_info_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Java gateway process exited before sending its port number"
     ]
    }
   ],
   "source": [
    "#.master(\"spark://10.152.183.12:7077\") \\\n",
    "#.master('k8s://10.152.183.1:16443') \\\n",
    "\n",
    "# Create a Spark Session\n",
    "spark = SparkSession \\\n",
    ".builder \\\n",
    ".master(\"spark://10.152.183.12:7077\") \\\n",
    ".config('spark.submit.deployMode', 'cluster') \\\n",
    ".appName('Sparkify') \\\n",
    ".getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-84901cd22f32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and store it into a Spark dataframe\n",
    "\n",
    "# Read in full sparkify dataset\n",
    "#event_data = \"s3n://udacity-dsnd/sparkify/sparkify_event_data.json\"\n",
    "event_data = \"mini_sparkify_event_data.json\"\n",
    "df = spark.read.json(event_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- artist: string (nullable = true)\n",
      " |-- auth: string (nullable = true)\n",
      " |-- firstName: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- itemInSession: long (nullable = true)\n",
      " |-- lastName: string (nullable = true)\n",
      " |-- length: double (nullable = true)\n",
      " |-- level: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- method: string (nullable = true)\n",
      " |-- page: string (nullable = true)\n",
      " |-- registration: long (nullable = true)\n",
      " |-- sessionId: long (nullable = true)\n",
      " |-- song: string (nullable = true)\n",
      " |-- status: long (nullable = true)\n",
      " |-- ts: long (nullable = true)\n",
      " |-- userAgent: string (nullable = true)\n",
      " |-- userId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Structure of the dataframe\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the smaller Sparkify dataframe\n",
    "nrows = df.count()\n",
    "ncols = len(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286500\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(nrows)\n",
    "print(ncols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "226"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Obtain the number of distinct users in the full Sparkify dataset\n",
    "df.select(['userId']).dropDuplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                page| count|\n",
      "+--------------------+------+\n",
      "|            NextSong|228108|\n",
      "|                Home| 14457|\n",
      "|           Thumbs Up| 12551|\n",
      "|     Add to Playlist|  6526|\n",
      "|          Add Friend|  4277|\n",
      "|         Roll Advert|  3933|\n",
      "|               Login|  3241|\n",
      "|              Logout|  3226|\n",
      "|         Thumbs Down|  2546|\n",
      "|           Downgrade|  2055|\n",
      "|                Help|  1726|\n",
      "|            Settings|  1514|\n",
      "|               About|   924|\n",
      "|             Upgrade|   499|\n",
      "|       Save Settings|   310|\n",
      "|               Error|   258|\n",
      "|      Submit Upgrade|   159|\n",
      "|    Submit Downgrade|    63|\n",
      "|              Cancel|    52|\n",
      "|Cancellation Conf...|    52|\n",
      "|            Register|    18|\n",
      "| Submit Registration|     5|\n",
      "+--------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Obtain the distribution of the interaction types in the analyzed dataset\n",
    "df.groupby('page').count().sort('count', ascending = False).show(22)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering and Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default observation start and end timestamps for users who haven't registered after October 1, or churned\n",
    "obs_start_default = 1538352000000\n",
    "obs_end_default = 1543622400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lag the page column\n",
    "windowsession = Window.partitionBy('sessionId').orderBy('ts')\n",
    "df = df.withColumn(\"lagged_page\", lag(df.page).over(windowsession))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All the values calculated here are the same for all logs belonging to a given user. \n",
    "windowuser = Window.partitionBy('userId').orderBy('ts').rangeBetween(Window.unboundedPreceding, Window.unboundedFollowing)\n",
    "\n",
    "# Identify users that registered after the start of observation, and infer the start date accordingly\n",
    "df = df.withColumn(\"beforefirstlog\", first(col('lagged_page')).over(windowuser))\n",
    "df = df.withColumn(\"firstlogtime\", first(col('ts')).over(windowuser))\n",
    "df = df.withColumn(\"obsstart\", \n",
    "                   when(df.beforefirstlog == \"Submit Registration\", df.firstlogtime).otherwise(obs_start_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify users that cancelled their service, i.e. users whose last log event is \"Cancellation Confirmation\", and\n",
    "# obtain the corresponding end of the observation period. This is done on the original dataset\n",
    "# so a single value, end of observation period, is copied to all rows belonging to a given userId.\n",
    "\n",
    "df = df.withColumn(\"endstate\", last(col('page')).over(windowuser))\n",
    "df = df.withColumn(\"lastlogtime\", last(col('ts')).over(windowuser))\n",
    "df = df.withColumn(\"obsend\", when(df.endstate == \"Cancellation Confirmation\", df.lastlogtime).otherwise(obs_end_default))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each log compute the time from the beginning of observation...\n",
    "df = df.withColumn(\"timefromstart\", col('ts')-col(\"obsstart\"))\n",
    "# ...and time before the end of observation\n",
    "df = df.withColumn(\"timebeforeend\", col('obsend')-col('ts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain user's last subscription level and add it to the original dataset\n",
    "df = df.withColumn(\"lastlevel\", last(col('level')).over(windowuser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing userId \n",
    "df = df.where(df.userId != \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with corrupted timestamp\n",
    "df = df.where(df.ts < obs_end_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the estimation window for activity trend calculation\n",
    "trend_est_days = 14\n",
    "trend_est_hours = trend_est_days * 24\n",
    "# In timestamp format\n",
    "trend_est = trend_est_days * 24 * 60 * 60 * 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregation by userId\n",
    "df_user = df.groupby('userId')\\\n",
    ".agg(\n",
    "     # User-level features\n",
    "     first(when(col('lastlevel') == 'paid', 1).otherwise(0)).alias('lastlevel'),\n",
    "     first(when(col('gender') == \"F\", 1).otherwise(0)).alias('gender'),\n",
    "     first(col('obsstart')).alias('obsstart'),\n",
    "     first(col('obsend')).alias('obsend'),\n",
    "     first(col('endstate')).alias('endstate'),\n",
    "     #first(col('location')).alias('location'),\n",
    "     #first(col('userAgent')).alias('userAgent')\n",
    "     #first(col('registration')).alias('registration'),\n",
    "     \n",
    "     # Aggregated activity statistics\n",
    "     count(col('page')).alias('nact'),\n",
    "     Fsum(when(col('page') == \"NextSong\", 1).otherwise(0)).alias(\"nsongs\"),\n",
    "     Fsum(when(col('page') == \"Thumbs Up\", 1).otherwise(0)).alias(\"ntbup\"),\n",
    "     Fsum(when(col('page') == \"Thumbs Down\", 1).otherwise(0)).alias(\"ntbdown\"),\n",
    "     Fsum(when(col('page') == \"Add Friend\", 1).otherwise(0)).alias(\"nfriend\"),\n",
    "     Fsum(when(col('page') == \"Add to Playlist\", 1).otherwise(0)).alias(\"nplaylist\"),     \n",
    "     Fsum(when(col('page') == \"Submit Downgrade\", 1).otherwise(0)).alias(\"ndgrade\"),\n",
    "     Fsum(when(col('page') == \"Submit Upgrade\", 1).otherwise(0)).alias(\"nugrade\"),\n",
    "     Fsum(when(col('page') == \"Home\", 1).otherwise(0)).alias(\"nhome\"),\n",
    "     Fsum(when(col('page') == \"Roll Advert\", 1).otherwise(0)).alias(\"nadvert\"),\n",
    "     Fsum(when(col('page') == \"Help\", 1).otherwise(0)).alias(\"nhelp\"),\n",
    "     Fsum(when(col('page') == \"Settings\", 1).otherwise(0)).alias(\"nsettings\"),\n",
    "     Fsum(when(col('page') == \"Error\", 1).otherwise(0)).alias(\"nerror\"),\n",
    "     \n",
    "     # Aggregated activity statistics in different periods \n",
    "     Fsum(when(col('timebeforeend') < trend_est, 1).otherwise(0)).alias(\"nact_recent\"),\n",
    "     Fsum(when(col('timefromstart') < trend_est, 1).otherwise(0)).alias(\"nact_oldest\"),\n",
    "     Fsum(when((col('page') == \"NextSong\") & (col('timebeforeend') < trend_est), 1).otherwise(0)).alias(\"nsongs_recent\"),\n",
    "     Fsum(when((col('page') == \"NextSong\") & (col('timefromstart') < trend_est), 1).otherwise(0)).alias(\"nsongs_oldest\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of the defined features that will be used for identifying churned users\n",
    "# The first added column, 'obshours', represents the length of the user-specific observation period in hours. The column \n",
    "# is not one of the features but is used to calculate all aggregated statistics per hour\n",
    "df_user = df_user.withColumn('obshours', (col('obsend') - col('obsstart'))/1000/3600)\\\n",
    ".withColumn('nact_perh', col('nact') / col('obshours'))\\\n",
    ".withColumn('nsongs_perh', col('nsongs') / col('obshours'))\\\n",
    ".withColumn('ntbup_perh', col('ntbup') / col('obshours'))\\\n",
    ".withColumn('ntbdown_perh', col('ntbdown') / col('obshours'))\\\n",
    ".withColumn('nfriend_perh', col('nfriend') / col('obshours'))\\\n",
    ".withColumn('nplaylist_perh', col('nplaylist') / col('obshours'))\\\n",
    ".withColumn('nhome_perh', col('nhome') / col('obshours'))\\\n",
    ".withColumn('nadvert_perh', col('nadvert') / col('obshours'))\\\n",
    ".withColumn('nerror_perh', col('nerror') / col('obshours'))\\\n",
    ".withColumn('upgradedowngrade', col('nugrade') + col('ndgrade'))\\\n",
    ".withColumn('songratio', col('nsongs') / col('nact'))\\\n",
    ".withColumn('positiveratio', (col('ntbup') + col('nfriend') + col('nplaylist')) / col('nact'))\\\n",
    ".withColumn('negativeratio', (col('ntbdown') + col('nhelp') + col('nerror') + col('nsettings')) / col('nact'))\\\n",
    ".withColumn('updownratio', col('ntbup') / (col('ntbdown') + 0.1))\\\n",
    ".withColumn('nact_recent_perh', col('nact_recent') / trend_est_hours)\\\n",
    ".withColumn('nact_oldest_perh', col('nact_oldest') / trend_est_hours)\\\n",
    ".withColumn('nsongs_recent_perh', col('nsongs_recent') / trend_est_hours)\\\n",
    ".withColumn('nsongs_oldest_perh', col('nsongs_oldest') / trend_est_hours)\\\n",
    ".withColumn('trend_act', (col('nact_recent_perh') - col('nact_oldest_perh')) / col('obshours'))\\\n",
    ".withColumn('trend_songs', (col('nsongs_recent_perh') - col('nsongs_oldest_perh')) / col('obshours'))\n",
    "#.withColumn('timesincereg', (col('obsstart') - col('registration'))/1000/3600)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of user's average number of items per session\n",
    "session_avgnitems = df.groupby(['userId', 'sessionId'])\\\n",
    ".agg(Fmax(col('itemInSession')).alias('nitems'))\\\n",
    ".groupby('userId').agg(avg(col('nitems')).alias('avgsessionitems'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculation of user's average session length\n",
    "session_avglength = df.groupby(['userId', 'sessionId'])\\\n",
    ".agg(Fmin(col('ts')).alias('startsession'), Fmax(col('ts')).alias('endsession'))\\\n",
    ".groupby('userId').agg(avg(col('endsession')-col('startsession')).alias('avgsessionlength'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculations to obtain user's average number of songs played between home visits\n",
    "windowhome = (Window.partitionBy('userId').orderBy('ts').rangeBetween(Window.unboundedPreceding, 0))\n",
    "df = df.withColumn(\"phasehome\", Fsum(when(df.page == \"Home\", 1).otherwise(0)).over(windowhome))\n",
    "\n",
    "songs_home = df.groupby(['userId', 'phasehome'])\\\n",
    ".agg(Fsum(when(col('page') == \"NextSong\", 1).otherwise(0)).alias('total'))\\\n",
    ".groupby('userId').agg(avg(col('total')).alias('avgsongs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the extra features to the df_user dataset with all other engineered features\n",
    "df_user = df_user\\\n",
    ".join(session_avgnitems, on = 'userId')\\\n",
    ".join(session_avglength, on = 'userId')\\\n",
    ".join(songs_home, on = 'userId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the binary response variable\n",
    "df_user = df_user.withColumn('label', when(df_user.endstate == \"Cancellation Confirmation\", 1).otherwise(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|   52|\n",
      "|    0|  173|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Distribution of the binary response variable\n",
    "df_user.groupby('label').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- lastlevel: integer (nullable = true)\n",
      " |-- gender: integer (nullable = true)\n",
      " |-- obsstart: long (nullable = true)\n",
      " |-- obsend: long (nullable = true)\n",
      " |-- endstate: string (nullable = true)\n",
      " |-- nact: long (nullable = false)\n",
      " |-- nsongs: long (nullable = true)\n",
      " |-- ntbup: long (nullable = true)\n",
      " |-- ntbdown: long (nullable = true)\n",
      " |-- nfriend: long (nullable = true)\n",
      " |-- nplaylist: long (nullable = true)\n",
      " |-- ndgrade: long (nullable = true)\n",
      " |-- nugrade: long (nullable = true)\n",
      " |-- nhome: long (nullable = true)\n",
      " |-- nadvert: long (nullable = true)\n",
      " |-- nhelp: long (nullable = true)\n",
      " |-- nsettings: long (nullable = true)\n",
      " |-- nerror: long (nullable = true)\n",
      " |-- nact_recent: long (nullable = true)\n",
      " |-- nact_oldest: long (nullable = true)\n",
      " |-- nsongs_recent: long (nullable = true)\n",
      " |-- nsongs_oldest: long (nullable = true)\n",
      " |-- obshours: double (nullable = true)\n",
      " |-- nact_perh: double (nullable = true)\n",
      " |-- nsongs_perh: double (nullable = true)\n",
      " |-- ntbup_perh: double (nullable = true)\n",
      " |-- ntbdown_perh: double (nullable = true)\n",
      " |-- nfriend_perh: double (nullable = true)\n",
      " |-- nplaylist_perh: double (nullable = true)\n",
      " |-- nhome_perh: double (nullable = true)\n",
      " |-- nadvert_perh: double (nullable = true)\n",
      " |-- nerror_perh: double (nullable = true)\n",
      " |-- upgradedowngrade: long (nullable = true)\n",
      " |-- songratio: double (nullable = true)\n",
      " |-- positiveratio: double (nullable = true)\n",
      " |-- negativeratio: double (nullable = true)\n",
      " |-- updownratio: double (nullable = true)\n",
      " |-- nact_recent_perh: double (nullable = true)\n",
      " |-- nact_oldest_perh: double (nullable = true)\n",
      " |-- nsongs_recent_perh: double (nullable = true)\n",
      " |-- nsongs_oldest_perh: double (nullable = true)\n",
      " |-- trend_act: double (nullable = true)\n",
      " |-- trend_songs: double (nullable = true)\n",
      " |-- avgsessionitems: double (nullable = true)\n",
      " |-- avgsessionlength: double (nullable = true)\n",
      " |-- avgsongs: double (nullable = true)\n",
      " |-- label: integer (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Schema of the transformed dataset\n",
    "df_user.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packing together multiple features  using VectorAssembler\n",
    "numeric_columns = ['nsongs_perh', 'ntbup_perh','ntbdown_perh', 'nfriend_perh', \n",
    "'nadvert_perh', 'nerror_perh', 'upgradedowngrade', 'songratio', 'positiveratio','negativeratio', \n",
    "'updownratio', 'trend_songs', 'avgsessionitems','avgsongs']\n",
    "\n",
    "numeric_assembler = VectorAssembler(inputCols = numeric_columns, outputCol = \"numericvectorized\")\n",
    "\n",
    "# Standardizing all numerical features at the same time\n",
    "scaler = StandardScaler(inputCol = \"numericvectorized\", outputCol = \"numericscaled\", withStd = True, withMean = True)\n",
    "#scaler = Normalizer(inputCol=\"numericvectorized\", outputCol=\"numericscaled\")\n",
    "\n",
    "# Adding the two binary features\n",
    "binary_columns = ['lastlevel', 'gender']\n",
    "total_assembler = VectorAssembler(inputCols = binary_columns + [\"numericscaled\"], outputCol = \"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom F1 score evaluator that we can use instead of BinaryClassificationEvaluator() in grid search\n",
    "class F1score(Evaluator):\n",
    "\n",
    "    def __init__(self, predictionCol = \"prediction\", labelCol=\"label\"):\n",
    "        self.predictionCol = predictionCol\n",
    "        self.labelCol = labelCol\n",
    "\n",
    "    def _evaluate(self, dataset):\n",
    "        \n",
    "        # Calculate F1 score \n",
    "        tp = dataset.where((dataset.label == 1) & (dataset.prediction == 1)).count()\n",
    "        fp = dataset.where((dataset.label == 0) & (dataset.prediction == 1)).count()\n",
    "        tn = dataset.where((dataset.label == 0) & (dataset.prediction == 0)).count()\n",
    "        fn = dataset.where((dataset.label == 1) & (dataset.prediction == 0)).count()\n",
    "        \n",
    "        # Add epsilon to prevent division by zero\n",
    "        precision = tp / float(tp + fp + 0.00001)\n",
    "        recall = tp / float(tp + fn + 0.00001)\n",
    "        \n",
    "        f1 = 2 * precision * recall / float(precision + recall + 0.00001)\n",
    "        \n",
    "        return f1\n",
    "\n",
    "    def isLargerBetter(self):\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training (plus validation) and test set \n",
    "\n",
    "train_plus_val, test = df_user.randomSplit([0.8, 0.2], seed = 9) \n",
    "#ntotal = df_user.count()\n",
    "#ntrainval = train_plus_val.count()\n",
    "#ntest = ntotal - ntrainval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ntotal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-f1487646df01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntrainval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mntest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ntotal' is not defined"
     ]
    }
   ],
   "source": [
    "print(ntotal)\n",
    "print(ntrainval)\n",
    "print(ntest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining three different pipelines with three different classifiers, all with default parameters\n",
    "\n",
    "# Pipeline with logistic regression \n",
    "#lr =  LogisticRegression()\n",
    "#pipeline_lr = Pipeline(stages = [numeric_assembler, scaler, total_assembler, lr])\n",
    "\n",
    "# Pipeline with random forest classifier\n",
    "#rf = RandomForestClassifier()\n",
    "#pipeline_rf = Pipeline(stages = [numeric_assembler, scaler, total_assembler, rf])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Gradient Boost Tree Classifier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training:\n",
      "57\n"
     ]
    }
   ],
   "source": [
    "# Perform the grid search by fitting the grid search object\n",
    "gb1 = GBTClassifier(maxDepth = 5, maxIter = 20)\n",
    "pipeline_gb1 = Pipeline(stages = [numeric_assembler, scaler, total_assembler, gb1])\n",
    "\n",
    "start = time.time()\n",
    "model_gb1 = pipeline_gb1.fit(train_plus_val)\n",
    "end = time.time()\n",
    "print('Time spent for training:')\n",
    "print(round(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lastlevel', 'gender', 'nsongs_perh', 'ntbup_perh', 'ntbdown_perh', 'nfriend_perh', 'nadvert_perh', 'nerror_perh', 'upgradedowngrade', 'songratio', 'positiveratio', 'negativeratio', 'updownratio', 'trend_songs', 'avgsessionitems', 'avgsongs']\n",
      "[0.005104825443128455, 0.0493788365191495, 0.10981519074625323, 0.015911950761465714, 0.06173576097178391, 0.08222850783081057, 0.1282104679551398, 0.04612961253266942, 0.04130880981739381, 0.06407590351689041, 0.016244494577009303, 0.0525279905908681, 0.04537725407050713, 0.1342630131047828, 0.0993826751087338, 0.048304706453414045]\n"
     ]
    }
   ],
   "source": [
    "# Display feature importances\n",
    "importances = model_gb1.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = binary_columns + numeric_columns\n",
    "print(names)\n",
    "print(importances_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions on the test set\n",
    "results_gb1 = model_gb1.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gb1 AUC score:\n",
      "0.6982758620689654\n"
     ]
    }
   ],
   "source": [
    "# AUC score on the test set\n",
    "auc_evaluator = BinaryClassificationEvaluator()\n",
    "auc_gb1 = auc_evaluator.evaluate(results_gb1)\n",
    "print('Model gb1 AUC score:')\n",
    "print(auc_gb1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gb1 F1 score:\n",
      "0.2999949000766989\n"
     ]
    }
   ],
   "source": [
    "# F1 score on the test set\n",
    "f1_evaluator = F1score()\n",
    "f1score_gb1 = f1_evaluator._evaluate(results_gb1)\n",
    "print('Model gb1 F1 score:')\n",
    "print(f1score_gb1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Gradient Boost Tree Classifier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent for training:\n",
      "5861.0"
     ]
    }
   ],
   "source": [
    "# Perform the grid search by fitting the grid search object\n",
    "gb4 = GBTClassifier(maxDepth = 5, maxIter = 200)\n",
    "pipeline_gb4 = Pipeline(stages = [numeric_assembler, scaler, total_assembler, gb4])\n",
    "\n",
    "start = time.time()\n",
    "model_gb4 = pipeline_gb4.fit(train_plus_val)\n",
    "end = time.time()\n",
    "print('Time spent for training:')\n",
    "print(round(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lastlevel', 'gender', 'nsongs_perh', 'ntbup_perh', 'ntbdown_perh', 'nfriend_perh', 'nadvert_perh', 'nerror_perh', 'upgradedowngrade', 'songratio', 'positiveratio', 'negativeratio', 'updownratio', 'trend_songs', 'avgsessionitems', 'avgsongs']\n",
      "[0.013795342305289867, 0.003419130795754195, 0.05192724418392687, 0.023604481206826188, 0.18329355168409747, 0.060501586172062846, 0.0974098898402886, 0.2110401549499677, 0.02286163968506689, 0.04730318423769473, 0.04232860002653574, 0.043054343894025765, 0.036773157537074976, 0.07858267078570629, 0.046534988450475566, 0.03757003424520641]"
     ]
    }
   ],
   "source": [
    "# Display feature importances\n",
    "importances = model_gb4.stages[-1].featureImportances\n",
    "importances_list = [importances[i] for i in range(len(importances))]\n",
    "names = binary_columns + numeric_columns\n",
    "print(names)\n",
    "print(importances_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain predictions on the test set\n",
    "results_gb4 = model_gb4.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gb4 AUC score:\n",
      "0.980815674238"
     ]
    }
   ],
   "source": [
    "# AUC score on the test set\n",
    "auc_evaluator = BinaryClassificationEvaluator()\n",
    "auc_gb4 = auc_evaluator.evaluate(results_gb4)\n",
    "print('Model gb4 AUC score:')\n",
    "print(auc_gb4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model gb4 F1 score:\n",
      "0.855347479183"
     ]
    }
   ],
   "source": [
    "# F1 score on the test set\n",
    "f1_evaluator = F1score()\n",
    "f1score_gb4 = f1_evaluator._evaluate(results_gb4)\n",
    "print('Model gb4 F1 score:')\n",
    "print(f1score_gb4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
